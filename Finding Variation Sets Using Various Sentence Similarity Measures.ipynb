{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Semantic Analysis\n",
    "\n",
    "Latent Semantic Analysis (LSA) was basically the top of the line as far as word vectors were concerned before the word2vec model [cite] was developed. The long and short of it is that you do a term/document matrix and do a Singular-Value Decomposition (SVD) [cite] on it. The result removes variation from the character representations of words. \n",
    "\n",
    "## Techniques and Their Results\n",
    "\n",
    "### Word by Word\n",
    "\n",
    "This is sort of like levenstein matching, in that for each word in utterance_a, you compare it to each word in utterance_b, if the cosine similarity of the vectors is high enough, then it counts as a match. Despite cranking the similarity up to 0.999, the F1 score never broke 32, no matter how many components we had in the vectorizer. The Precision hovered somewhere around 20, while the recall was somewhere around 92.\n",
    "\n",
    "pyemd -> requirements.txt\n",
    "\n",
    "### Sentence Mean\n",
    "\n",
    "In this case, we average all the vectors in a sentence and then compare it to another sentence, whose vectors are also averaged. This method does increase our F1 score: 49 with 300 components to the SVD and a similarity threshold of 0.95. In addition it's worth noting that the precision is 46 and the recall is 54. So we have a much more balanced set.\n",
    "\n",
    "### Word Mover's Distance\n",
    "\n",
    "This is a novel concept, based on the 'Earth Mover's Distance'. From wikipedia:\n",
    "\n",
    ">In statistics, the earth mover's distance (EMD) is a measure of the distance between two probability distributions over a region D. In mathematics, this is known as the Wasserstein metric. Informally, if the distributions are interpreted as two different ways of piling up a certain amount of dirt over the region D, the EMD is the minimum cost of turning one pile into the other; where the cost is assumed to be amount of dirt moved times the distance by which it is moved.\n",
    "\n",
    "In our case, the difficulty of moving dirt is the cosine similarity between two words. A distance matrix between each word in each utterance is formed, and the shortest path between each individual words, such that there is only one path between each word (assuming an equal number of words, when there are unqual numbers of words, there can be multiple paths to a certain word).\n",
    "\n",
    "**Note:** This is a computationally intensive method.\n",
    "\n",
    "**References:**\n",
    "\n",
    "Kusner, Matt, et al. *\"From word embeddings to document distances.\"* International Conference on Machine Learning. 2015.\n",
    "\n",
    "Pele, Ofir, and Michael Werman. *\"Fast and robust Earth Mover's Distances.\"* ICCV. Vol. 9. 2009.\n",
    "\n",
    "Pele, Ofir, and Michael Werman. *\"A linear time histogram metric for improved sift matching.\"* European conference on computer vision. Springer, Berlin, Heidelberg, 2008.\n",
    "\n",
    "## Baseline\n",
    "\n",
    "Right now it doesn't make sense to compare it to anything with a concrete minimum matching. But if we hit an F1 score of 60, then I will consider this a viable option for detecting variation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utterances\n",
    "import evaluation\n",
    "import sys\n",
    "import difflib\n",
    "import collections\n",
    "import codecs\n",
    "import numpy as np\n",
    "from math import log\n",
    "from itertools import islice\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim import corpora\n",
    "from pyemd import emd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import varseta_accuracy_tester as vat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = (\"anch\", 3, 2)\n",
    "\n",
    "to_dos = [\n",
    "        (\"DATA/Swedish_MINGLE_dataset/plain/1\", \"DATA/Swedish_MINGLE_dataset/GOLD/1\"),\n",
    "        (\"DATA/Swedish_MINGLE_dataset/plain/2\", \"DATA/Swedish_MINGLE_dataset/GOLD/2\"),\n",
    "        (\"DATA/Swedish_MINGLE_dataset/plain/3\", \"DATA/Swedish_MINGLE_dataset/GOLD/3\"),\n",
    "        (\"DATA/Swedish_MINGLE_dataset/plain/4\", \"DATA/Swedish_MINGLE_dataset/GOLD/4\")]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in data\n",
    "\n",
    "Things to note:\n",
    "I'm using only the lowercase versions, considering the corpus size, this can change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in: DATA/Swedish_MINGLE_dataset/plain/1\n",
      "Reading in: DATA/Swedish_MINGLE_dataset/plain/2\n",
      "Reading in: DATA/Swedish_MINGLE_dataset/plain/3\n",
      "Reading in: DATA/Swedish_MINGLE_dataset/plain/4\n"
     ]
    }
   ],
   "source": [
    "all_utterances = []\n",
    "for to_do in to_dos:\n",
    "    print(\"Reading in: \" + to_do[0])\n",
    "    u = utterances.Utterances(to_do[0], to_do[1])\n",
    "    gold_utterances = u._goldutterances\n",
    "\n",
    "    utterances_reformatted = []\n",
    "    ids = []\n",
    "\n",
    "    for utterance in u._utterances:\n",
    "        new_utt = utterance[2].split()\n",
    "        new_utt = [i.lower() for i in new_utt]\n",
    "        utterances_reformatted.append(new_utt)\n",
    "        ids.append((utterance[0], utterance[1]))\n",
    "        \n",
    "    all_utterances = all_utterances + utterances_reformatted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-idf\n",
    "\n",
    "The first step is to build a tf-idf matrix. For our purposes, each utterance will be a document. This may change down the line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _dummy_preprocessor(to_return):\n",
    "    \"\"\"This is a workaround for the TfidfVectorizer's tokenizer\"\"\"\n",
    "    return to_return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer(analyzer='word',\n",
    "                         tokenizer=_dummy_preprocessor,\n",
    "                         preprocessor=_dummy_preprocessor,\n",
    "                         token_pattern=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<4660x1101 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 16818 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_features = tf_idf.fit_transform(all_utterances)\n",
    "tf_idf_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the SVD\n",
    "\n",
    "Note, we can put all this in a pipeline, but I think it's a little more explecit if we just go through each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsa = TruncatedSVD(n_components=400, \n",
    "                   algorithm='randomized',\n",
    "                   n_iter=7, random_state=69)\n",
    "\n",
    "test_dense_corpus = lsa.fit_transform(tf_idf_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.51364892e-01, -2.31301547e-01,  1.16082492e-01, ...,\n",
       "        -4.08167856e-04,  1.04575443e-04,  2.07873373e-04],\n",
       "       [ 1.46198434e-01,  2.32317490e-01,  7.58477293e-03, ...,\n",
       "        -4.50809077e-04, -9.40323514e-04,  2.30051817e-04],\n",
       "       [ 4.49652796e-02,  7.92418302e-02,  9.63618728e-03, ...,\n",
       "         4.70855383e-03,  5.37170895e-03,  2.18235174e-03],\n",
       "       ...,\n",
       "       [ 3.59692288e-01,  1.90604597e-02, -8.16234413e-02, ...,\n",
       "         3.95780257e-03,  2.01106691e-04,  3.70454178e-03],\n",
       "       [ 4.20428058e-02,  1.31244813e-01, -1.60543821e-01, ...,\n",
       "        -2.35938225e-02, -2.88579328e-02,  1.29561837e-02],\n",
       "       [ 5.82134770e-02,  2.08614156e-01, -2.59514807e-01, ...,\n",
       "         3.07040632e-03, -3.30577309e-03, -1.97216009e-04]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_dense_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.29011349e-03,  2.52727211e-03, -6.34374583e-04,\n",
       "         5.55326881e-03, -2.39245892e-04, -1.48188405e-03,\n",
       "        -8.16205523e-04,  8.42298315e-04, -5.04169499e-03,\n",
       "        -2.30353937e-06, -2.36536407e-03, -2.89080734e-03,\n",
       "        -1.18691833e-03, -3.04637112e-03,  2.09389575e-03,\n",
       "        -2.18931324e-04, -3.96857868e-03,  1.26094287e-02,\n",
       "         6.75262110e-03,  3.08682847e-03,  3.75317972e-03,\n",
       "        -2.40704326e-03, -1.56736219e-03,  2.42793778e-03,\n",
       "         8.20005555e-04, -1.04234354e-03,  8.62725451e-03,\n",
       "         2.07788970e-03,  2.97357074e-03, -5.56152645e-03,\n",
       "        -4.86703384e-03, -2.18052368e-03, -8.87272118e-04,\n",
       "        -7.30859899e-04, -1.10543256e-03,  2.74002328e-04,\n",
       "        -4.39753718e-03, -2.51085806e-04, -1.23747915e-03,\n",
       "        -1.52308022e-03, -4.99930786e-03, -7.37726700e-03,\n",
       "        -1.84185587e-03,  3.44898674e-03,  3.63050591e-03,\n",
       "        -2.83417619e-03, -2.31814295e-03, -2.04832542e-03,\n",
       "         2.62849610e-02, -6.32743844e-03,  8.94120616e-04,\n",
       "         1.41333045e-03, -4.29163177e-03, -7.02401770e-04,\n",
       "        -1.13219072e-03, -6.24426400e-03, -3.60601231e-03,\n",
       "         5.63223783e-04, -7.31775167e-03,  2.92013699e-03,\n",
       "         1.48730415e-03, -4.19810130e-03, -1.58889729e-03,\n",
       "         7.24813504e-03, -1.00365892e-02, -1.21939182e-02,\n",
       "         1.38889536e-03,  8.93954730e-03,  2.85418729e-03,\n",
       "        -7.52931710e-03, -4.88012495e-03, -4.00317332e-03,\n",
       "        -9.45927470e-03,  8.68114482e-03, -1.42926479e-02,\n",
       "         3.18632900e-02,  1.92416137e-03, -3.37690247e-02,\n",
       "        -1.57374165e-02, -9.27117675e-03,  8.06861952e-02,\n",
       "         7.91361776e-02, -1.49162133e-01,  3.50653061e-02,\n",
       "         2.12139083e-02, -1.47867503e-01, -2.45604869e-01,\n",
       "         9.15706012e-01, -9.12586367e-02,  1.08785257e-01,\n",
       "        -3.85173511e-02, -2.99359466e-02,  3.17881146e-02,\n",
       "        -7.24230845e-03,  1.11774687e-02,  1.74392455e-02,\n",
       "         5.07563552e-03, -5.71737244e-03, -1.16303141e-02,\n",
       "         4.14718373e-03, -3.42523582e-03, -4.23146523e-03,\n",
       "         9.91552758e-03,  1.11947049e-02,  4.48363148e-03,\n",
       "        -1.94730320e-02, -2.83747158e-03, -6.86217365e-04,\n",
       "        -1.41349042e-03,  8.83986522e-03, -2.62141679e-03,\n",
       "        -3.35602851e-04, -5.97059565e-03,  1.66364605e-03,\n",
       "        -2.03923328e-02,  2.47826937e-03, -6.13615355e-03,\n",
       "         9.28730527e-03,  5.58614463e-04,  1.04851567e-02,\n",
       "        -1.23545525e-03,  1.28085586e-03,  6.12517689e-04,\n",
       "         2.39546565e-02,  2.77678051e-03, -1.49555363e-04,\n",
       "        -4.94263323e-03, -9.50615642e-04,  2.92245383e-03,\n",
       "        -6.19001888e-04, -1.55851312e-04,  3.18348717e-03,\n",
       "         3.74990741e-03,  1.77149311e-03,  4.52796305e-05,\n",
       "        -2.10051418e-03,  4.73117237e-03,  4.29081350e-03,\n",
       "        -6.29369731e-04,  7.93197883e-03,  3.18679668e-03,\n",
       "        -3.24053959e-03,  1.71572460e-03,  2.22370102e-03,\n",
       "         5.26409559e-04, -2.14471339e-03,  5.60285373e-04,\n",
       "        -6.80930456e-03, -3.52493762e-03, -6.72862030e-03,\n",
       "        -8.56973921e-03, -7.42124048e-02, -4.76167289e-02,\n",
       "         4.75015255e-04,  5.68730722e-03,  1.11834188e-03,\n",
       "        -4.57649468e-03, -1.26677641e-03, -1.14834780e-03,\n",
       "        -9.87930650e-04, -1.52532477e-03, -1.04886517e-03,\n",
       "        -1.66347185e-03,  3.29440366e-03,  4.46731636e-04,\n",
       "         1.73700226e-03, -1.45132239e-03, -3.02856337e-04,\n",
       "        -4.79764259e-04, -4.93979843e-05,  7.87771427e-05,\n",
       "         3.64117807e-04, -2.10277968e-04, -1.70061652e-03,\n",
       "        -1.04317613e-03, -3.69438044e-04, -1.91350993e-03,\n",
       "         4.67074746e-04, -2.60867539e-03,  1.38703207e-03,\n",
       "        -1.98056732e-04,  2.04960966e-03,  8.13890272e-04,\n",
       "         2.96969655e-04, -1.64452773e-03,  5.39903758e-04,\n",
       "         9.31762484e-04,  1.65251994e-04,  9.01157303e-04,\n",
       "        -5.55700354e-04,  1.00551819e-03, -1.79908822e-03,\n",
       "        -1.65611293e-03,  4.57408772e-04, -1.40696362e-03,\n",
       "         1.97265027e-04, -1.38108749e-04, -1.70404607e-03,\n",
       "         1.70496083e-04,  2.36687613e-03,  2.25080956e-03,\n",
       "         7.02613717e-04, -1.12794958e-03,  3.52792801e-03,\n",
       "         3.03636782e-03,  4.01234571e-03,  5.65551634e-04,\n",
       "         1.04255227e-03,  6.15106833e-04, -1.10219392e-03,\n",
       "         4.94089955e-04,  1.02629145e-03,  1.97048652e-03,\n",
       "         4.76082766e-03,  6.02344543e-04,  1.68792495e-03,\n",
       "         1.35131960e-03,  9.98514420e-05,  2.51460438e-03,\n",
       "         1.25489018e-03, -5.49667359e-05, -2.29193428e-03,\n",
       "         8.75591924e-08, -6.08884649e-04, -8.33342698e-03,\n",
       "         1.13196496e-03,  9.26157760e-05, -6.42359555e-03,\n",
       "         2.55747729e-03,  5.98516394e-03,  1.77567911e-03,\n",
       "        -4.14031872e-03,  3.72106847e-03, -1.47865794e-03,\n",
       "        -1.94389979e-03, -7.47611600e-04, -8.95999968e-04,\n",
       "        -5.70065780e-04, -1.13311462e-03,  9.22891804e-03,\n",
       "        -9.21352995e-04,  6.15997866e-03, -4.55669285e-03,\n",
       "        -3.90796014e-03,  4.28290081e-04, -9.84868961e-04,\n",
       "        -2.46980056e-03,  6.56029309e-04, -2.65228007e-03,\n",
       "        -1.89464414e-03, -2.76612388e-03, -6.29843700e-04,\n",
       "         2.79484892e-04,  2.64033912e-03, -4.59766404e-03,\n",
       "        -6.54162146e-04,  1.49510736e-03, -5.81891040e-05,\n",
       "        -3.05744181e-03,  7.57306564e-04,  3.27721707e-04,\n",
       "        -1.49509820e-03,  1.80199825e-03, -2.21518223e-03,\n",
       "         1.42477150e-03,  7.78273684e-05, -2.03324374e-03,\n",
       "         1.08582753e-03, -7.09800912e-04, -1.06483895e-03,\n",
       "         2.19519714e-03,  2.38458876e-03,  3.64409067e-04,\n",
       "        -1.46706265e-03, -7.46757983e-04,  8.38173940e-04,\n",
       "        -2.32191119e-03,  1.14127600e-03,  1.07018429e-05,\n",
       "        -1.00624167e-03, -3.86911105e-03, -1.27414684e-03,\n",
       "        -6.52896664e-04, -4.34745291e-03,  4.78693298e-03,\n",
       "        -4.16032370e-04,  4.20532651e-03,  1.84954067e-03,\n",
       "         1.93325488e-03, -4.17237178e-03,  2.66619235e-03,\n",
       "        -4.42139099e-03,  9.47463506e-04, -5.93551243e-05,\n",
       "         1.70153214e-03,  1.37001151e-03,  1.86406214e-03,\n",
       "         1.85607756e-03,  4.30833652e-04, -1.54704707e-03,\n",
       "         2.02764955e-04,  8.49778387e-04,  1.26642887e-04,\n",
       "         1.31759763e-03,  4.83573762e-05,  2.77116178e-05,\n",
       "         1.11771546e-04, -9.13853163e-05,  7.12522433e-05,\n",
       "         1.09917624e-04, -1.25296595e-04,  1.03406298e-03,\n",
       "        -3.20290937e-04, -3.03279905e-03, -2.27470391e-03,\n",
       "        -2.48305729e-03, -3.72662007e-04,  6.28232685e-04,\n",
       "         1.18081946e-03,  5.88535891e-04, -2.70022425e-03,\n",
       "        -9.46797362e-05,  1.09017680e-05,  2.14361345e-04,\n",
       "         1.33737476e-04,  2.59513194e-04, -2.06580616e-04,\n",
       "        -3.30015755e-04,  1.64182378e-03,  3.38617570e-05,\n",
       "         9.18985749e-04, -7.11748282e-05,  8.17963381e-04,\n",
       "         7.15255236e-04,  2.72261188e-04,  5.08822065e-04,\n",
       "        -1.23348808e-03,  1.13383480e-03,  7.89402890e-04,\n",
       "         6.43564011e-04, -3.25060260e-04, -1.63765902e-04,\n",
       "         1.08341445e-03,  1.09312928e-03,  4.18037017e-04,\n",
       "         8.58897378e-04, -7.94472257e-04,  1.58606351e-03,\n",
       "         1.04336917e-03,  3.09240315e-05,  6.18737300e-04,\n",
       "        -7.47198940e-04, -2.64808195e-05, -4.47314647e-04,\n",
       "        -1.25515642e-03,  1.10767754e-03,  7.14854123e-04,\n",
       "         1.93607209e-03,  7.35666575e-04, -4.30060924e-04,\n",
       "         9.45956791e-04,  3.69924760e-03, -8.49252334e-04,\n",
       "        -1.29627482e-04, -1.99861484e-03, -8.71562643e-04,\n",
       "         1.82694826e-03,  2.00601640e-03,  1.30871007e-03,\n",
       "        -1.31221569e-04,  1.11814555e-03, -6.62225308e-04,\n",
       "        -2.49012596e-04, -3.65221983e-04, -3.74349735e-05,\n",
       "         9.80166946e-04, -2.15691899e-04, -3.73463376e-04,\n",
       "         2.22763121e-04,  4.09298437e-04, -9.06344034e-05,\n",
       "        -7.36547160e-04,  4.67621676e-05,  7.31175750e-04,\n",
       "         3.29864912e-04,  6.50634494e-04, -1.94393607e-04,\n",
       "         1.82011779e-04,  7.42646075e-04, -1.96299014e-04,\n",
       "        -1.40118721e-04,  4.32679699e-05,  4.48675709e-04,\n",
       "        -3.51708910e-04,  2.74406780e-04,  7.68456680e-05,\n",
       "         1.55988972e-07, -3.58908257e-04,  5.67562339e-04,\n",
       "        -4.67511647e-04]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_a = lsa.transform(tf_idf.transform([\"ja\"]))\n",
    "test_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 400)\n",
      "[[-0.00012748]]\n",
      "[[0.68189472]]\n",
      "[[-0.00308386]]\n",
      "[[1.]]\n"
     ]
    }
   ],
   "source": [
    "# yes\n",
    "test_a = lsa.transform(tf_idf.transform([\"ja\"]))\n",
    "print(test_a.shape)\n",
    "\n",
    "# no\n",
    "test_b = lsa.transform(tf_idf.transform([u'n\\xe4']))\n",
    "\n",
    "# maybe (according to an online dictionary)\n",
    "test_c = lsa.transform(tf_idf.transform([u'kanske']))\n",
    "\n",
    "# yes -> no\n",
    "print(cosine_similarity(test_a, test_b))\n",
    "\n",
    "# yes -> maybe\n",
    "print(cosine_similarity(test_a, test_c))\n",
    "\n",
    "# no -> maybe (interesting!)\n",
    "print(cosine_similarity(test_b, test_c))\n",
    "\n",
    "# no -> no\n",
    "print(cosine_similarity(test_b, test_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word by Word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = (\"anch\", 3, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy functions\n",
    "\n",
    "These are functions to track the precision, recall and f1 scores of the methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_dict_init():\n",
    "    \"\"\"Initialize the precision, recall, f1 tracker\"\"\"\n",
    "    confusion = {\"fuzzy_precisions\" : list(),\n",
    "                 \"strict_precisions\" : list(),\n",
    "                 \"fuzzy_recalls\" : list(),\n",
    "                 \"strict_recalls\" : list(),\n",
    "                 \"fuzzy_f1s\" : list(),\n",
    "                 \"strict_f1s\" : list()\n",
    "                 }\n",
    "    \n",
    "    return confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_and_print(confusion_dict, evaluation_stats):\n",
    "    \"\"\"Update precision, recall, f1 stats and print their values\"\"\"\n",
    "    confusion_dict[\"fuzzy_precisions\"].append(evaluation_stats.fuzzy_precision)\n",
    "    confusion_dict[\"strict_precisions\"].append(evaluation_stats.strict_precision)\n",
    "    confusion_dict[\"fuzzy_recalls\"].append(evaluation_stats.fuzzy_recall)\n",
    "    confusion_dict[\"strict_recalls\"].append(evaluation_stats.strict_recall)\n",
    "    confusion_dict[\"fuzzy_f1s\"].append(evaluation_stats.fuzzy_f1)\n",
    "    confusion_dict[\"strict_f1s\"].append(evaluation_stats.strict_f1)\n",
    "    \n",
    "    \n",
    "\n",
    "    print('\\tFuzzy Precision: {:0.2f}'.format(evaluation_stats.fuzzy_precision))\n",
    "    print('\\tFuzzy Recall: {:0.2f}'.format(evaluation_stats.fuzzy_recall))\n",
    "    print('\\tFuzzy F1: {:0.2f}'.format(evaluation_stats.fuzzy_f1))\n",
    "    print('')\n",
    "    print('\\tStrict Precision: {:0.2f}'.format(evaluation_stats.strict_precision))\n",
    "    print('\\tStrict Recall: {:0.2f}'.format(evaluation_stats.strict_recall))\n",
    "    print('\\tStrict F1: {:0.2f}'.format(evaluation_stats.strict_f1))\n",
    "    print('\\n')\n",
    "    \n",
    "    return confusion_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_stats_print(confusion_dict):\n",
    "    \"\"\"Calculate final precision, recall and f1\"\"\"\n",
    "    \n",
    "    avg_fuzzy_precision = sum([i for i in confusion_dict[\"fuzzy_precisions\"]])/len(confusion_dict[\"fuzzy_precisions\"])\n",
    "    avg_fuzzy_recall = sum([i for i in confusion_dict[\"fuzzy_recalls\"]])/len(confusion_dict[\"fuzzy_recalls\"])\n",
    "    avg_fuzzy_f1 = sum([i for i in confusion_dict[\"fuzzy_f1s\"]])/len(confusion_dict[\"fuzzy_f1s\"])\n",
    "    avg_strict_precision = sum([i for i in confusion_dict[\"strict_precisions\"]])/len(confusion_dict[\"strict_precisions\"])\n",
    "    avg_strict_recall = sum([i for i in confusion_dict[\"strict_recalls\"]])/len(confusion_dict[\"strict_recalls\"])\n",
    "    avg_strict_f1 = sum([i for i in confusion_dict[\"strict_f1s\"]])/len(confusion_dict[\"strict_f1s\"])\n",
    "\n",
    "\n",
    "    print(\"\\n-------------------\")\n",
    "    print('\\nAverage Scores:')\n",
    "    print('\\tAverage Fuzzy Precision: {:0.2f}'.format(avg_fuzzy_precision))\n",
    "    print('\\tAverage Fuzzy Recall: {:0.2f}'.format(avg_fuzzy_recall))\n",
    "    print('\\tAverage Fuzzy F1: {:0.2f}'.format(avg_fuzzy_f1))\n",
    "    print('')\n",
    "    print('\\tAverage Strict Precision: {:0.2f}'.format(avg_strict_precision))\n",
    "    print('\\tAverage Strict Recall: {:0.2f}'.format(avg_strict_recall))\n",
    "    print('\\tAverage Strict F1: {:0.2f}'.format(avg_strict_f1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_matcher(a_vectors, b_vectors, similarity, minimum_matches):\n",
    "    \"\"\"Return True if a sentence takes the correct number of matches\n",
    "    \n",
    "    Parameters:\n",
    "    a_vectors:\n",
    "        List of vectors, semantic representation of a sentence\n",
    "    b_vectors:\n",
    "        List of vectors, semantic representation of a sentence\n",
    "    similarity:\n",
    "        Semantic similarity threshold for a match\n",
    "    minimum_matches:\n",
    "        Number of matches threshold to be considered a variation set\"\"\"\n",
    "    \n",
    "    matches = 0\n",
    "    \n",
    "    for vector_a in a_vectors:\n",
    "        for vector_b in b_vectors:\n",
    "            cos_similarity = cosine_similarity(vector_a.reshape(1, -1), vector_b.reshape(1, -1))[0][0]\n",
    "            if cos_similarity > similarity:\n",
    "                matches += 1\n",
    "             \n",
    "    if matches >= minimum_matches:\n",
    "        return True\n",
    "                \n",
    "    return False\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matches wrapper\n",
    "\n",
    "This is similar to the `matches_anchor` function found in `../variation_sets/processing/utils.py` but edit to work with cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matches_anchor_lsa(it, minimum_matches, match_type, overlap, return_count=True, ids=None):\n",
    "    \"\"\"Returns varation set matches using anchor method\"\"\"\n",
    "\n",
    "    matches = 0\n",
    "    matches_list = []\n",
    "\n",
    "    for count, i in enumerate(it):\n",
    "        utterances = iter(i)\n",
    "        first = next(utterances)\n",
    "        first = [j.lower() for j in first]\n",
    "        first_vector = lsa.transform(tf_idf.transform(first))\n",
    "        \n",
    "        for utterance in utterances:\n",
    "            utterance = [j.lower() for j in utterance]\n",
    "            utterance_vector = lsa.transform(tf_idf.transform(utterance))\n",
    "            if cosine_similarity_matcher(first_vector, utterance_vector, overlap, args[2]):\n",
    "                matches += 1\n",
    "                if ids:\n",
    "                    matches_list.append((ids[count], i))\n",
    "                else:\n",
    "                    matches_list.append(i)\n",
    "\n",
    "    if return_count:\n",
    "        return matches\n",
    "    else:\n",
    "        return matches_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding variation sets in: DATA/Swedish_MINGLE_dataset/plain/1\n",
      "\tFuzzy Precision: 0.33\n",
      "\tFuzzy Recall: 0.92\n",
      "\tFuzzy F1: 0.49\n",
      "\n",
      "\tStrict Precision: 0.07\n",
      "\tStrict Recall: 0.19\n",
      "\tStrict F1: 0.10\n",
      "\n",
      "\n",
      "Finding variation sets in: DATA/Swedish_MINGLE_dataset/plain/2\n",
      "\tFuzzy Precision: 0.23\n",
      "\tFuzzy Recall: 0.85\n",
      "\tFuzzy F1: 0.36\n",
      "\n",
      "\tStrict Precision: 0.05\n",
      "\tStrict Recall: 0.18\n",
      "\tStrict F1: 0.08\n",
      "\n",
      "\n",
      "Finding variation sets in: DATA/Swedish_MINGLE_dataset/plain/3\n",
      "\tFuzzy Precision: 0.17\n",
      "\tFuzzy Recall: 0.93\n",
      "\tFuzzy F1: 0.28\n",
      "\n",
      "\tStrict Precision: 0.04\n",
      "\tStrict Recall: 0.22\n",
      "\tStrict F1: 0.07\n",
      "\n",
      "\n",
      "Finding variation sets in: DATA/Swedish_MINGLE_dataset/plain/4\n",
      "\tFuzzy Precision: 0.08\n",
      "\tFuzzy Recall: 0.97\n",
      "\tFuzzy F1: 0.14\n",
      "\n",
      "\tStrict Precision: 0.00\n",
      "\tStrict Recall: 0.05\n",
      "\tStrict F1: 0.01\n",
      "\n",
      "\n",
      "\n",
      "-------------------\n",
      "\n",
      "Average Scores:\n",
      "\tAverage Fuzzy Precision: 0.20\n",
      "\tAverage Fuzzy Recall: 0.92\n",
      "\tAverage Fuzzy F1: 0.32\n",
      "\n",
      "\tAverage Strict Precision: 0.04\n",
      "\tAverage Strict Recall: 0.16\n",
      "\tAverage Strict F1: 0.06\n"
     ]
    }
   ],
   "source": [
    "confusion_stats = confusion_dict_init()\n",
    "\n",
    "similarity = 0.9999\n",
    "\n",
    "for to_do in to_dos:\n",
    "    print(\"Finding variation sets in: \" + to_do[0])\n",
    "    u = utterances.Utterances(to_do[0], to_do[1])\n",
    "    gold_utterances = u._goldutterances\n",
    "\n",
    "    utterances_reformatted = []\n",
    "    ids = []\n",
    "\n",
    "    for utterance in u._utterances:\n",
    "        new_utt = utterance[2].split()\n",
    "        \n",
    "        utterances_reformatted.append(new_utt)\n",
    "        ids.append((utterance[0], utterance[1]))\n",
    "\n",
    "    utt_iter = vat.window(utterances_reformatted, args[1])\n",
    "    id_iter = vat.window(ids, args[1])\n",
    "    ids = [i for i in id_iter]\n",
    "    ids_and_matches = matches_anchor_lsa(utt_iter, args[2], None, similarity, False, ids=ids)\n",
    "    combined = vat.convert_varseta_format(ids_and_matches)\n",
    "\n",
    "    varseta_eval = evaluation.Evaluation(combined, gold_utterances)\n",
    "    \n",
    "    confusion_stats = update_and_print(confusion_stats, varseta_eval)\n",
    "    \n",
    "final_stats_print(confusion_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Sentences\n",
    "\n",
    "The way this technique works is for each utterance, you average the vectors of each word into the sentance and then compare the cosine similarity of those sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_averager(vectors):\n",
    "    \"\"\"Average a series of vectors into one vector\"\"\"\n",
    "    \n",
    "    return np.mean(vectors, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matches_anchor_lsa_sentences(it, minimum_matches, match_type, overlap, return_count=True, ids=None):\n",
    "    \"\"\"Return varation set matches using anchor method\"\"\"\n",
    "\n",
    "\n",
    "    \n",
    "    matches = 0\n",
    "    matches_list = []\n",
    "\n",
    "    for count, i in enumerate(it):\n",
    "        utterances = iter(i)\n",
    "        first = next(utterances)\n",
    "        first = [j.lower() for j in first]\n",
    "        first_vector = lsa.transform(tf_idf.transform(first))\n",
    "        first_vector = vector_averager(first_vector)\n",
    "        \n",
    "        for utterance in utterances:\n",
    "            utterance = [j.lower() for j in utterance]\n",
    "            utterance_vector = lsa.transform(tf_idf.transform(utterance))\n",
    "            utterance_vector = vector_averager(utterance_vector)\n",
    "            if cosine_similarity(first_vector.reshape(1, -1), utterance_vector.reshape(1, -1)) > overlap:\n",
    "                matches += 1\n",
    "                if ids:\n",
    "                    matches_list.append((ids[count], i))\n",
    "                else:\n",
    "                    matches_list.append(i)\n",
    "\n",
    "\n",
    "    if return_count:\n",
    "        return matches\n",
    "    else:\n",
    "        return matches_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding variation sets inDATA/Swedish_MINGLE_dataset/plain/1\n",
      "\tFuzzy Precision: 0.63\n",
      "\tFuzzy Recall: 0.60\n",
      "\tFuzzy F1: 0.62\n",
      "\n",
      "\tStrict Precision: 0.08\n",
      "\tStrict Recall: 0.07\n",
      "\tStrict F1: 0.07\n",
      "\n",
      "\n",
      "Finding variation sets inDATA/Swedish_MINGLE_dataset/plain/2\n",
      "\tFuzzy Precision: 0.51\n",
      "\tFuzzy Recall: 0.50\n",
      "\tFuzzy F1: 0.50\n",
      "\n",
      "\tStrict Precision: 0.10\n",
      "\tStrict Recall: 0.10\n",
      "\tStrict F1: 0.10\n",
      "\n",
      "\n",
      "Finding variation sets inDATA/Swedish_MINGLE_dataset/plain/3\n",
      "\tFuzzy Precision: 0.45\n",
      "\tFuzzy Recall: 0.47\n",
      "\tFuzzy F1: 0.46\n",
      "\n",
      "\tStrict Precision: 0.08\n",
      "\tStrict Recall: 0.09\n",
      "\tStrict F1: 0.09\n",
      "\n",
      "\n",
      "Finding variation sets inDATA/Swedish_MINGLE_dataset/plain/4\n",
      "\tFuzzy Precision: 0.27\n",
      "\tFuzzy Recall: 0.38\n",
      "\tFuzzy F1: 0.32\n",
      "\n",
      "\tStrict Precision: 0.00\n",
      "\tStrict Recall: 0.00\n",
      "\tStrict F1: 0.00\n",
      "\n",
      "\n",
      "\n",
      "-------------------\n",
      "\n",
      "Average Scores:\n",
      "\tAverage Fuzzy Precision: 0.46\n",
      "\tAverage Fuzzy Recall: 0.49\n",
      "\tAverage Fuzzy F1: 0.47\n",
      "\n",
      "\tAverage Strict Precision: 0.06\n",
      "\tAverage Strict Recall: 0.06\n",
      "\tAverage Strict F1: 0.06\n"
     ]
    }
   ],
   "source": [
    "confusion_stats = confusion_dict_init()\n",
    "\n",
    "similarity = 0.95\n",
    "\n",
    "for to_do in to_dos:\n",
    "    print(\"Finding variation sets in\" + to_do[0])\n",
    "    u = utterances.Utterances(to_do[0], to_do[1])\n",
    "    gold_utterances = u._goldutterances\n",
    "    utterances_reformatted = []\n",
    "    ids = []\n",
    "\n",
    "    for utterance in u._utterances:\n",
    "        new_utt = utterance[2].split()\n",
    "        utterances_reformatted.append(new_utt)\n",
    "        ids.append((utterance[0], utterance[1]))\n",
    "        \n",
    "    utt_iter = vat.window(utterances_reformatted, args[1])\n",
    "    id_iter = vat.window(ids, args[1])\n",
    "    ids = [i for i in id_iter]\n",
    "    ids_and_matches = matches_anchor_lsa_sentences(utt_iter, args[2], None, similarity, False, ids=ids)\n",
    "    \n",
    "    combined = vat.convert_varseta_format(ids_and_matches)\n",
    "\n",
    "    varseta_eval = evaluation.Evaluation(combined, gold_utterances)\n",
    "    \n",
    "    confusion_stats = update_and_print(confusion_stats, varseta_eval)\n",
    "    \n",
    "final_stats_print(confusion_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Averages with smoothing\n",
    "\n",
    "This is an implementation of (Arora et al. 2016). The long and short as that you smooth based off of the frequency of the word. I'm skeptical, as the LSA was done on tf-idf, but it has performed well in semantic matching (in English and with word2vec vectors).\n",
    "\n",
    "Before smoothing we get our value:\n",
    "$$\\Sigma_w v_w$$\n",
    "\n",
    "But then we add a smoothing element alpha:\n",
    "\n",
    "$$\\alpha _w = \\frac{a}{a + p_w}$$\n",
    "\n",
    "Where $p_w$ is the frequency of *w* in the corpus and *a* is some hyperparameter (0.0001 is used in the paper). Making our final formula for each summed vector:\n",
    "\n",
    "$$\\Sigma _w \\alpha_w v_w$$\n",
    "\n",
    "### Results\n",
    "\n",
    "It has the same F1 Score, but a MUCH higher recall.\n",
    "\n",
    ">Average Scores:\n",
    "\n",
    ">\tAverage Fuzzy Precision: 0.37\n",
    "\n",
    ">\tAverage Fuzzy Recall: 0.68\n",
    "\n",
    ">\tAverage Fuzzy F1: 0.47\n",
    ">\n",
    ">\tAverage Strict Precision: 0.06\n",
    "\n",
    ">\tAverage Strict Recall: 0.10\n",
    "\n",
    ">\tAverage Strict F1: 0.07\n",
    "\n",
    "Arora, Sanjeev, Yingyu Liang, and Tengyu Ma. *\"A simple but tough-to-beat baseline for sentence embeddings.\"* (2016)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth_vector(words, vectors, counter):\n",
    "    \n",
    "    a = 0.01\n",
    "    \n",
    "    alpha_list = []\n",
    "    \n",
    "    for word in words:\n",
    "        value = a/(a + float(counter[word]))\n",
    "        alpha_list.append([value])\n",
    "        \n",
    "    alphas = np.array(alpha_list)\n",
    "    \n",
    "    return alphas * vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matches_anchor_smoothed_lsa_sentences(it, minimum_matches, match_type, overlap, word_counts, return_count=True, ids=None):\n",
    "    \"\"\"Return varation set matches using anchor method\"\"\"\n",
    "    \n",
    "    matches = 0\n",
    "    matches_list = []\n",
    "\n",
    "    for count, i in enumerate(it):\n",
    "        utterances = iter(i)\n",
    "        first = next(utterances)\n",
    "        first = [j.lower() for j in first]\n",
    "        first_vector = lsa.transform(tf_idf.transform(first))\n",
    "        \n",
    "        first_vector = smooth_vector(first, first_vector, word_counts)\n",
    "        first_vector = vector_averager(first_vector)\n",
    "        \n",
    "        for utterance in utterances:\n",
    "            utterance = [j.lower() for j in utterance]\n",
    "            utterance_vector = lsa.transform(tf_idf.transform(utterance))\n",
    "            utterance_vector = smooth_vector(utterance, utterance_vector, word_counts)\n",
    "            utterance_vector = vector_averager(utterance_vector)\n",
    "            if cosine_similarity(first_vector.reshape(1, -1), utterance_vector.reshape(1, -1)) > overlap:\n",
    "                matches += 1\n",
    "                if ids:\n",
    "                    matches_list.append((ids[count], i))\n",
    "                else:\n",
    "                    matches_list.append(i)\n",
    "\n",
    "\n",
    "    if return_count:\n",
    "        return matches\n",
    "    else:\n",
    "        return matches_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding variation sets inDATA/Swedish_MINGLE_dataset/plain/1\n",
      "\tFuzzy Precision: 0.48\n",
      "\tFuzzy Recall: 0.79\n",
      "\tFuzzy F1: 0.60\n",
      "\n",
      "\tStrict Precision: 0.08\n",
      "\tStrict Recall: 0.13\n",
      "\tStrict F1: 0.10\n",
      "\n",
      "\n",
      "Finding variation sets inDATA/Swedish_MINGLE_dataset/plain/2\n",
      "\tFuzzy Precision: 0.41\n",
      "\tFuzzy Recall: 0.64\n",
      "\tFuzzy F1: 0.50\n",
      "\n",
      "\tStrict Precision: 0.07\n",
      "\tStrict Recall: 0.12\n",
      "\tStrict F1: 0.09\n",
      "\n",
      "\n",
      "Finding variation sets inDATA/Swedish_MINGLE_dataset/plain/3\n",
      "\tFuzzy Precision: 0.35\n",
      "\tFuzzy Recall: 0.69\n",
      "\tFuzzy F1: 0.46\n",
      "\n",
      "\tStrict Precision: 0.06\n",
      "\tStrict Recall: 0.11\n",
      "\tStrict F1: 0.08\n",
      "\n",
      "\n",
      "Finding variation sets inDATA/Swedish_MINGLE_dataset/plain/4\n",
      "\tFuzzy Precision: 0.22\n",
      "\tFuzzy Recall: 0.59\n",
      "\tFuzzy F1: 0.32\n",
      "\n",
      "\tStrict Precision: 0.02\n",
      "\tStrict Recall: 0.05\n",
      "\tStrict F1: 0.03\n",
      "\n",
      "\n",
      "\n",
      "-------------------\n",
      "\n",
      "Average Scores:\n",
      "\tAverage Fuzzy Precision: 0.36\n",
      "\tAverage Fuzzy Recall: 0.68\n",
      "\tAverage Fuzzy F1: 0.47\n",
      "\n",
      "\tAverage Strict Precision: 0.06\n",
      "\tAverage Strict Recall: 0.10\n",
      "\tAverage Strict F1: 0.07\n"
     ]
    }
   ],
   "source": [
    "confusion_stats = confusion_dict_init()\n",
    "\n",
    "similarity = 0.96\n",
    "\n",
    "\n",
    "# get word counts\n",
    "word_counts = collections.Counter()\n",
    "[word_counts.update(i) for i in all_utterances]\n",
    "\n",
    "for to_do in to_dos:\n",
    "    print(\"Finding variation sets in\" + to_do[0])\n",
    "    u = utterances.Utterances(to_do[0], to_do[1])\n",
    "    gold_utterances = u._goldutterances\n",
    "    utterances_reformatted = []\n",
    "    ids = []\n",
    "\n",
    "    for utterance in u._utterances:\n",
    "        new_utt = utterance[2].split()\n",
    "        utterances_reformatted.append(new_utt)\n",
    "        ids.append((utterance[0], utterance[1]))\n",
    "        \n",
    "    utt_iter = vat.window(utterances_reformatted, args[1])\n",
    "    id_iter = vat.window(ids, args[1])\n",
    "    ids = [i for i in id_iter]\n",
    "    ids_and_matches = matches_anchor_smoothed_lsa_sentences(utt_iter,\n",
    "                                                            args[2],\n",
    "                                                            None,\n",
    "                                                            similarity,\n",
    "                                                            word_counts,\n",
    "                                                            False,\n",
    "                                                            ids=ids)\n",
    "    \n",
    "    combined = vat.convert_varseta_format(ids_and_matches)\n",
    "\n",
    "    varseta_eval = evaluation.Evaluation(combined, gold_utterances)\n",
    "    \n",
    "    confusion_stats = update_and_print(confusion_stats, varseta_eval)\n",
    "    \n",
    "final_stats_print(confusion_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Mover's Distance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wmdistance(lsa, document1, document2):\n",
    "    \"\"\"Compute the Word Mover's Distance between two documents.\n",
    "    Parameters\n",
    "    ----------\n",
    "    lsa: an sklearn dense TrunkcatedSVD matrix\n",
    "        to generate vectors\n",
    "    document1 : list of str\n",
    "        Input document.\n",
    "    document2 : list of str\n",
    "        Input document.\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        Word Mover's distance between `document1` and `document2`.\n",
    "    Warnings\n",
    "    --------\n",
    "    This method only works if `pyemd <https://pypi.org/project/pyemd/>`_ is installed.\n",
    "    If one of the documents have no words that exist in the vocab, `float('inf')` (i.e. infinity)\n",
    "    will be returned.\n",
    "    Raises\n",
    "    ------\n",
    "    ImportError\n",
    "        If `pyemd <https://pypi.org/project/pyemd/>`_  isn't installed.\n",
    "    \"\"\"\n",
    "#     if not PYEMD_EXT:\n",
    "#         raise ImportError(\"Please install pyemd Python package to compute WMD.\")\n",
    "        \n",
    "    dictionary = corpora.Dictionary(documents=[document1, document2])\n",
    "    vocab_len = len(dictionary)\n",
    "\n",
    "    # Sets for faster look-up.\n",
    "    docset1 = set(document1)\n",
    "    docset2 = set(document2)\n",
    "\n",
    "    # Compute distance matrix.\n",
    "    distance_matrix = np.zeros((vocab_len, vocab_len), dtype=np.double)\n",
    "    for i, t1 in dictionary.items():\n",
    "        for j, t2 in dictionary.items():\n",
    "            if t1 not in docset1 or t2 not in docset2:\n",
    "                continue\n",
    "            # Compute Euclidean distance between word vectors.\n",
    "            distance_matrix[i, j] = np.sqrt(np.sum((lsa.transform(tf_idf.transform([t1])) - lsa.transform(tf_idf.transform([t2])))**2))\n",
    "            \n",
    "    if np.sum(distance_matrix) == 0.0:\n",
    "        # `emd` gets stuck if the distance matrix contains only zeros.\n",
    "        return float('inf')\n",
    "\n",
    "    def nbow(document):\n",
    "        d = np.zeros(vocab_len, dtype=np.double)\n",
    "        nbow = dictionary.doc2bow(document)  # Word frequencies.\n",
    "        doc_len = len(document)\n",
    "        for idx, freq in nbow:\n",
    "            d[idx] = freq / float(doc_len)  # Normalized word frequencies.\n",
    "        return d\n",
    "\n",
    "    # Compute nBOW representation of documents.\n",
    "    d1 = nbow(document1)\n",
    "    d2 = nbow(document2)\n",
    "\n",
    "    # Compute WMD.\n",
    "    return emd(d1, d2, distance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matches_anchor_wmd(it, minimum_matches, match_type, overlap, lsa, return_count=True, ids=None):\n",
    "    \"\"\"Return varation set matches using anchor method\"\"\"\n",
    "    matches = 0\n",
    "    matches_list = []\n",
    "\n",
    "    for count, i in enumerate(it):\n",
    "        utterances = iter(i)\n",
    "        first = next(utterances)\n",
    "        first = [j.lower() for j in first]\n",
    "        \n",
    "        for utterance in utterances:\n",
    "            utterance = [j.lower() for j in utterance]\n",
    "\n",
    "            if wmdistance(lsa, first, utterance) < overlap:\n",
    "                matches += 1\n",
    "                if ids:\n",
    "                    matches_list.append((ids[count], i))\n",
    "                else:\n",
    "                    matches_list.append(i)\n",
    "\n",
    "\n",
    "    if return_count:\n",
    "        return matches\n",
    "    else:\n",
    "        return matches_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inf\n",
      "[u'ja']\n",
      "[u's\\xe5', u'!']\n",
      "1.3976866697\n"
     ]
    }
   ],
   "source": [
    "print(wmdistance(lsa, [u'ja'], [u'ja', u'ja']))\n",
    "print(all_utterances[0])\n",
    "print(all_utterances[1])\n",
    "\n",
    "print(wmdistance(lsa, all_utterances[0], all_utterances[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding variation sets inDATA/Swedish_MINGLE_dataset/plain/1\n"
     ]
    }
   ],
   "source": [
    "confusion_stats = confusion_dict_init()\n",
    "\n",
    "similarity = 0.40\n",
    "\n",
    "for to_do in to_dos:\n",
    "    print(\"Finding variation sets in\" + to_do[0])\n",
    "    u = utterances.Utterances(to_do[0], to_do[1])\n",
    "    gold_utterances = u._goldutterances\n",
    "    utterances_reformatted = []\n",
    "    ids = []\n",
    "\n",
    "    for utterance in u._utterances:\n",
    "        new_utt = utterance[2].split()\n",
    "        utterances_reformatted.append(new_utt)\n",
    "        ids.append((utterance[0], utterance[1]))\n",
    "        \n",
    "    utt_iter = vat.window(utterances_reformatted, args[1])\n",
    "    id_iter = vat.window(ids, args[1])\n",
    "    ids = [i for i in id_iter]\n",
    "    ids_and_matches = matches_anchor_wmd(utt_iter, args[2], None, similarity, lsa, False, ids=ids)\n",
    "    combined = vat.convert_varseta_format(ids_and_matches)\n",
    "\n",
    "    varseta_eval = evaluation.Evaluation(combined, gold_utterances)\n",
    "\n",
    "    confusion_stats = update_and_print(confusion_stats, varseta_eval)\n",
    "    \n",
    "final_stats_print(confusion_stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
